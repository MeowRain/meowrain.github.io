<a href="https://blog.csdn.net/qq_44703886/article/details/122817463">【基础理论】图像梯度(Image Gradient)概念和求解</a>

# 一、图像梯度的概念
图像梯度是指图像某像素在x和y两个方向上的变化率（与相邻像素比较），是一个二维向量，由2个分量组成X轴的变化、Y轴的变化 。其中：

X轴的变化是指当前像素右侧（X加1）的像素值减去当前像素左侧（X减1）的像素值。

Y轴的变化是当前像素下方（Y加1）的像素值减去当前像素上方（Y减1）的像素值。

计算出来这2个分量，形成一个二维向量，就得到了该像素的图像梯度。取反正切arctan，可得到梯度角度。

## 梯度幅度

梯度的幅度，也称为梯度的模，是衡量函数在某一点处沿着某一方向变化率大小的量。它是一个标量值，表示梯度向量的大小。以下是梯度幅度的相关介绍：

### 梯度幅度的定义
梯度幅度是函数在某一点处沿着某一方向变化率的最大值，即梯度向量的模

。

### 梯度幅度的计算公式
梯度的幅度可以通过计算梯度向量的模得到

### 梯度幅度的应用
梯度幅度在图像处理、机器学习等领域中非常有用，尤其是在边缘检测、特征提取等任务中。通过计算图像中每个点的梯度幅度，可以确定图像中变化最快的区域，即边缘
。

通过以上解释，我们可以看到梯度幅度不仅是数学中的一个重要概念，而且在实际应用中也有着广泛的应用。

# 二、与图像梯度有关的相关函数

## 2.1 filter函数

filter2D函数是OpenCV库中的一种滤波方法，用于对图像进行二维卷积操作
```c++
void filter2D(InputArray src, OutputArray dst, int ddepth, InputArray kernel, Point anchor = Point(-1, -1), double delta = 0, int borderType = BORDER_DEFAULT);
```

下面是filter2D函数的各个参数的详细说明：

src：输入图像，可以是任意类型的单通道或多通道图像。

dst：输出图像，大小和通道数与输入图像相同。输出图像的类型可以由参数ddepth指定。

ddepth：输出图像的深度，例如CV_8U（8位无符号整数）、CV_32F（32位浮点数）等。如果未指定（值为-1），则输出图像的深度与输入图像相同。

kernel：卷积核，通常是一个二维矩阵。卷积核的大小和类型决定了滤波操作的效果。

anchor：卷积核的锚点（anchor point），默认值为(-1, -1)，表示锚点位于卷积核的中心。锚点用于确定卷积核在图像中的位置。

delta：可选参数，用于在将结果写入输出图像之前添加到每个像素的值上。默认值为0。

borderType：边界处理模式，用于处理图像边缘处的像素。默认值为BORDER_DEFAULT，表示使用默认的边界处理方式。其他可用的边界处理模式包括BORDER_CONSTANT（使用常数填充边界）、BORDER_REPLICATE（复制边缘像素填充边界）等。

filter2D函数的工作原理是将卷积核应用于输入图像的每个像素及其邻域，从而计算出输出图像中对应像素的值。卷积核在图像上滑动，其锚点与图像中的每个像素对齐。在每个位置上，卷积核与其覆盖的图像区域进行逐元素的乘法和求和操作，得到输出图像中对应像素的值。

filter2D函数非常灵活，可以用于实现各种线性滤波操作，如平滑滤波、锐化滤波、边缘检测等。只需选择合适的卷积核即可实现不同的滤波效果。

## 2.2magnitude函数

magnitude函数是OpenCV库中的一个函数，用于计算复数向量的幅度（或称为模）
```c++
void magnitude(InputArray x, InputArray y, OutputArray magnitude);
```
magnitude函数接受以下参数：

x：第一个输入数组，表示复数的实部。这通常是一个浮点数类型的数组。

y：第二个输入数组，表示复数的虚部。这同样是一个浮点数类型的数组。x和y应该具有相同的尺寸和数据类型。

magnitude：输出数组，用于存储计算得到的幅度值。输出数组的大小和类型与输入数组相同。

magnitude函数的工作原理是对输入数组x和y中的每对元素（实部和虚部）执行以下操作：

计算复数的平方和：real_part^2 + imaginary_part^2。

对结果开平方根，得到复数的幅度（模）：sqrt(real_part^2 + imaginary_part^2)。

最后，将计算得到的幅度值存储在输出数组magnitude中。

在图像处理领域，magnitude函数通常用于计算梯度图像的幅度。例如，在计算Sobel算子或Robert算子等梯度算子时，可以使用magnitude函数合并x方向和y方向的梯度，得到梯度的幅度图像。这种梯度幅度图像有助于突出图像中的边缘和纹理信息。

# 三、图像锐化及边缘检测

<a href="https://www.cnblogs.com/noticeable/p/10896398.html">OpenCV实现图像的空间滤波——图像锐化及边缘检测</a>

# 1.robert算子

```c++
void robert_grad(const Mat& src, Mat &dst)
{
    Mat grad_x, grad_y;
 
    Mat kernel_x = (Mat_<float>(2, 2) << -1, 0, 0, 1);
    Mat kernel_y = (Mat_<float>(2, 2) << 0, -1, 1, 0);
 
    filter2D(src, grad_x, CV_32F, kernel_x);
    filter2D(src, grad_y, CV_32F, kernel_y);
 
    //convertScaleAbs(grad_x, grad_x);
    //convertScaleAbs(grad_y, grad_y);
    //addWeighted(grad_x, 1, grad_y, 1, 0, dst);
    magnitude(grad_x, grad_y, dst);
    convertScaleAbs(dst, dst);
}
```

# 2.sobel算子
自我实现：
```c++
bool Sobel(const Mat& image, Mat& result, int TYPE)
{
    if (image.channels() != 1)
        return false;
    // 系数设置
    int kx(0);
    int ky(0);
    if (TYPE == 0) {
        kx = 0; ky = 1;
    }
    else if (TYPE == 1) {
        kx = 1; ky = 0;
    }
    else if (TYPE == 2) {
        kx = 1; ky = 1;
    }
    else
        return false;
 
    // 设置mask
    float mask[3][3] = { {1,2,1},{0,0,0},{-1,-2,-1} };
    Mat y_mask = Mat(3, 3, CV_32F, mask) / 8;
    Mat x_mask = y_mask.t(); // 转置
 
    // 计算x方向和y方向上的滤波
    Mat sobelX, sobelY;
    filter2D(image, sobelX, CV_32F, x_mask);
    filter2D(image, sobelY, CV_32F, y_mask);
    sobelX = abs(sobelX);
    sobelY = abs(sobelY);
    // 梯度图
    Mat gradient = kx * sobelX.mul(sobelX) + ky * sobelY.mul(sobelY);
 
    // 计算阈值
    int scale = 4;
    double cutoff = scale * mean(gradient)[0];
 
    result.create(image.size(), image.type());
    result.setTo(0);
    for (int i = 1; i < image.rows - 1; i++)
    {
        float* sbxPtr = sobelX.ptr<float>(i);
        float* sbyPtr = sobelY.ptr<float>(i);
        float* prePtr = gradient.ptr<float>(i - 1);
        float* curPtr = gradient.ptr<float>(i);
        float* lstPtr = gradient.ptr<float>(i + 1);
        uchar* rstPtr = result.ptr<uchar>(i);
        // 阈值化和极大值抑制
        for (int j = 1; j < image.cols - 1; j++)
        {
            if (curPtr[j] > cutoff && (
                (sbxPtr[j] > kx*sbyPtr[j] && curPtr[j] > curPtr[j - 1] && curPtr[j] > curPtr[j + 1]) ||
                (sbyPtr[j] > ky*sbxPtr[j] && curPtr[j] > prePtr[j] && curPtr[j] > lstPtr[j])))
                rstPtr[j] = 255;
        }
    }
 
    return true;
}
```

调用api:

```c++
Sobel(
 
                InputArray Src // 输入图像
 
                OutputArray dst// 输出图像，大小与输入图像一致
 
                int depth // 输出图像深度.
 
                Int dx.  // X方向，几阶导数
 
                int dy // Y方向，几阶导数.
 
                int ksize, SOBEL算子kernel大小，必须是1、3、5、7、
 
                double scale  = 1
 
                double delta = 0
 
                int borderType = BORDER_DEFAULT
 
        )
```

eg:
```c++
int main()
{
    Mat img = imread("111.jpg");

    imshow("原始图", img);

    Mat grad_x, grad_y;
    Mat abs_grad_x, abs_grad_y, dst;

    //求x方向梯度
    Sobel(img, grad_x, CV_16S, 1, 0, 3, 1, 1, BORDER_DEFAULT);
    convertScaleAbs(grad_x, abs_grad_x);
    imshow("x方向soble", abs_grad_x);

    //求y方向梯度
    Sobel(img, grad_y, CV_16S, 0, 1, 3, 1, 1, BORDER_DEFAULT);
    convertScaleAbs(grad_y, abs_grad_y);
    imshow("y向soble", abs_grad_y);

    //合并梯度
    addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, dst);
    imshow("整体方向soble", dst);


    waitKey(0);

}
```

# 三、Laplacian算子:

OpenCV提供的Laplacian的函数API为：
```c++
Laplacian( src_gray, dst, ddepth, kernel_size, scale, delta, BORDER_DEFAULT );
```
参数意义为，

src_gray，输入图像

dst，Laplace操作结果

ddepth，输出图像深度，因为输入图像一般为CV_8U，为了避免数据溢出，输出图像深度应该设置为CV_16S

滤波器孔径尺寸；

比例因子；

表示结果存入目标图

```c++
#include<opencv2\opencv.hpp>  
#include<opencv2\highgui\highgui.hpp>

using namespace std;
using namespace cv;

//边缘检测
int main()
{
    Mat img = imread("D:\\CODE\\vsCODE\\shiyan1\\Source\\test2.jpg");
    imshow("原始图", img);
    Mat gray, dst, abs_dst;
    //转换为灰度图
    cvtColor(img, gray, COLOR_RGB2GRAY);
    //使用Laplace函数
    //第三个参数：目标图像深度；第四个参数：滤波器孔径尺寸；第五个参数：比例因子；第六个参数：表示结果存入目标图
    Laplacian(gray, dst, CV_16S, 3, 1, 0, BORDER_DEFAULT);
    //计算绝对值，并将结果转为8位
    convertScaleAbs(dst, abs_dst);
    imshow("Laplacian图", abs_dst);
    waitKey(0);

}

```

# 4.LOG算子
步骤如下：
1. 对图像先进性高斯滤波（G × f），再进行Laplace算子运算Δ（G × f）；

2. 保留一阶导数峰值的位置，从中寻找Laplace过零点；

3. 对过零点的精确位置进行插值估计。寻找Laplace零点的原因是如果图像中有噪声，噪声在一阶导数处也会取得极大值从而被当作边缘。然而求解这个极大值也不方便，采用二阶导数后，极大值点就为0了，因此值为0的地方就是边界。

```c++
#include <opencv2/highgui/highgui.hpp>
#include "opencv2/imgproc/imgproc.hpp"
#include <iostream>
int main()
{
    cv::Mat srcImage =
        cv::imread("D:\\CODE\\vsCODE\\shiyan1\\Source\\test2.jpg", 0);
    if (!srcImage.data)
        return -1;

    // 高斯平滑
    GaussianBlur(srcImage, srcImage, cv::Size(3, 3),
        0, 0, cv::BORDER_DEFAULT);
    cv::Mat dstImage;
    // 拉普拉斯变换
    Laplacian(srcImage, dstImage, CV_16S, 3);
    convertScaleAbs(dstImage, dstImage);
    cv::imshow("srcImage", srcImage);
    cv::imshow("dstImage", dstImage);
    cv::waitKey(0);
    return 0;

}
```

# 五、导向滤波

向图滤波主要是通过一张引导图G，对目标图像P（输入图像）进行滤波处理，使得最后的输出图像大体上与目标图像P相似，但是纹理部分与引导图G相似。导向滤波不仅能够实现双边滤波的边缘平滑，而且在检测到边缘附近有很好的表现，可以应用在图像增强、HDR压缩、图像抠图以及图像去雾等场景中。

导向滤波实现步骤如下：

1. 利用boxFilter滤波器完成均值计算，其中均值包括导向均值、原始均值、互相关均值以及自相关均值

2. 根据均值计算相关系数参数，包括自相关与互相关方差。

3. 计算窗口线性变换参数系数a、b。

4. 根据公式计算参数a、b的均值。

5. 利用参数得到导向滤波输出矩阵S。

```c++
#include <iostream>
#include <opencv2\core\core.hpp>
#include <opencv2\highgui\highgui.hpp>
#include <opencv2\imgproc\imgproc.hpp>

using namespace cv;
using namespace std;

//导向滤波器
Mat guidedfilter(Mat& srcImage, Mat& srcClone, int r, double eps);

int main()
{
    Mat srcImage = imread("D:\\CODE\\vsCODE\\shiyan1\\Source\\test2.jpg");
    if (srcImage.empty())
    {
        cout << "读入图片错误！" << endl;
        system("pause");
        return -1;
    }
    //进行通道分离
    vector<Mat>vSrcImage, vResultImage;
    split(srcImage, vSrcImage);
    Mat resultMat;
    for (int i = 0; i < 3; i++)
    {
        //分通道转换成浮点型数据
        Mat tempImage;
        vSrcImage[i].convertTo(tempImage, CV_64FC1, 1.0 / 255.0);
        Mat p = tempImage.clone();
        //分别进行导向滤波
        Mat resultImage = guidedfilter(tempImage, p, 4, 0.01);
        vResultImage.push_back(resultImage);
    }
    //通道结果合并
    merge(vResultImage, resultMat);
    imshow("原图像", srcImage);
    imshow("导向滤波后图像", resultMat);
    waitKey(0);
    return 0;
}

Mat guidedfilter(Mat& srcImage, Mat& srcClone, int r, double eps)
{
    //转换源图像信息
    srcImage.convertTo(srcImage, CV_64FC1);
    srcClone.convertTo(srcClone, CV_64FC1);
    int NumRows = srcImage.rows;
    int NumCols = srcImage.cols;
    Mat boxResult;

    //下面按照步骤进行导向滤波操作
    /////////////////////////////////////////////////////////////
    //步骤一：计算均值
    boxFilter(Mat::ones(NumRows, NumCols, srcImage.type()),
        boxResult, CV_64FC1, Size(r, r));
    //生成导向均值mean_I
    Mat mean_I;
    boxFilter(srcImage, mean_I, CV_64FC1, Size(r, r));
    //生成原始均值mean_P
    Mat mean_P;
    boxFilter(srcClone, mean_P, CV_64FC1, Size(r, r));
    //生成互相关均值mean_IP
    Mat mean_IP;
    boxFilter(srcImage.mul(srcClone), mean_IP,
        CV_64FC1, Size(r, r));
    Mat cov_IP = mean_IP - mean_I.mul(mean_P);
    //生成自相关均值mean_II
    Mat mean_II;
    //应用盒滤波计算相关均值
    boxFilter(srcImage.mul(srcImage), mean_II, CV_64FC1, Size(r, r));
    //步骤二：计算相关系数
    Mat var_I = mean_II - mean_I.mul(mean_I);
    Mat var_IP = mean_IP - mean_I.mul(mean_P);
    //步骤三:计算参数系数a,b
    Mat a = cov_IP / (var_I + eps);
    Mat b = mean_P = a.mul(mean_I);
    //步骤四：计算系数a,b的均值
    Mat mean_a;
    boxFilter(a, mean_a, CV_64FC1, Size(r, r));
    mean_a = mean_a / boxResult;
    Mat mean_b;
    boxFilter(b, mean_b, CV_64FC1, Size(r, r));
    mean_b = mean_b / boxResult;
    //步骤五：生成输出矩阵
    Mat resultMat = mean_a.mul(srcImage) + mean_b;
    return resultMat;
}
```

# 六、canny算子————边缘检测方法的提出
```
　Canny算子是John F. Canny于 1986 年开发出来的一个多级边缘检测算法。Canny 的目标是找到一个最优的边缘检测算法，最优边缘检测的含义是：

(1)最优检测：算法能够尽可能多地标识出图像中的实际边缘，漏检真实边缘的概率和误检非边缘的概率都尽可能小；
(2)最优定位准则：检测到的边缘点的位置距离实际边缘点的位置最近，或者是由于噪声影响引起检测出的边缘偏离物体的真实边缘的程度最小；
(3)检测点与边缘点一一对应：算子检测的边缘点与实际边缘点应该是一一对应。
为了满足这些要求 Canny 使用了变分法（calculus of variations），这是一种寻找优化特定功能的函数的方法。最优检测使用四个指数函数项表示，但是它非常近似于高斯函数的一阶导数。
 
Canny边缘检测算法可以分为以下5个步骤：
应用高斯滤波来平滑图像，目的是去除噪声，任何边缘检测算法都不可能在未经处理的原始数据上很好地工作，所以第一步是对原始数据与高斯 mask 作卷积，得到的图像与原始图像相比有些轻微的模糊（blurred）。
找寻图像的强度梯度（intensity gradients），即找寻一幅图像中灰度强度变化最强的位置。
应用非最大抑制（non-maximum suppression）技术来消除边误检（本来不是但检测出来是）。就是保留了每个像素点上梯度强度的极大值，而删掉其他的值。
应用双阈值的方法来决定可能的（潜在的）边界
利用滞后技术来跟踪边界
```

## Canny算子API函数
```c++
void Canny(inputArray,outputArray,double threshold1,double threshold2,int apertureSize=3,bool L2gradient=false) 
*第一个参数，输入图像，且需为单通道8位图像。 
*第二个参数，输出的边缘图。 
*第三个参数，第一个滞后性阈值。用于边缘连接。 
*第四个参数，第二个滞后性阈值。用于控制强边缘的初始段，高低阈值比在2:1到3:1之间。 
*第五个参数，表明应用sobel算子的孔径大小，默认值为3。 
*第六个参数，bool类型L2gradient，一个计算图像梯度幅值的标识，默认值false。

```


```c++
#include<opencv2\opencv.hpp>  
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include<iostream>
#include"math.h"
using namespace std;
using namespace cv;

Mat Img_in, Img_gray, Img_out, Img_canny;
Mat scr;
int main()
{
    Img_in = imread("D:\\CODE\\vsCODE\\shiyan1\\Source\\test2.jpg");


    int rows = Img_in.rows;
    int cols = Img_in.cols;//获取图像尺寸

    cvtColor(Img_in, Img_gray, COLOR_RGB2GRAY);
    imshow("【灰度图】", Img_gray);//转化为灰度图


    //step1:高斯平滑
    Mat img_filt;
    GaussianBlur(Img_gray, Img_out, Size(3, 3), 0, 0);

    Canny(Img_out, Img_canny, 50, 150, 3);
    imshow("自带函数结果", Img_canny);

    //adaptiveThreshold(img_filt , Img_out , 255 ,ADAPTIVE_THRESH_MEAN_C , THRESH_BINARY,min(rows,cols), 0);
    //imshow("【二值图】",Img_out );
    Img_out.convertTo(Img_out, CV_32FC1); //将图像转换为float或double型，否则算梯度会报错

    /*step2:计算梯度（幅度和方向）
     选择一阶差分卷积模板：
     dx=[-1,-1;1,1] dy=[1,-1;1,-1]
    */
    Mat gy = (Mat_<char>(2, 2) << 1, -1,
        1, -1);
    //定义一阶差分卷积梯度模板
    Mat gx = (Mat_<char>(2, 2) << -1, -1,
        1, 1); //定义一阶差分卷积梯度模板
    Mat img_gx, img_gy, img_g;//定义矩阵
    Mat img_dir = Mat::zeros(rows, cols, CV_32FC1);//定义梯度方向矩阵,计算角度为float型

    filter2D(Img_out, img_gx, Img_out.depth(), gx);  //获取x方向的梯度图像.使用梯度模板进行二维卷积,结果与原图像大小相同
    filter2D(Img_out, img_gy, Img_out.depth(), gy);  //获取x方向的梯度图像.使用梯度模板进行二维卷积,结果与原图像大小相同
    img_gx = img_gx.mul(img_gx);//点乘（每个像素值平方）
    img_gy = img_gy.mul(img_gy);//点乘（每个像素值平方）
    img_g = img_gx + img_gy;
    sqrt(img_g, img_g); //梯度幅值图像
    imshow("梯度图", img_g);

    //求梯度方向图像
    for (int i = 0; i < rows; i++)
    {
        for (int j = 0; j < cols; j++)
        {
            img_dir.at<float>(i, j) = fastAtan2(img_gy.at<float>(i, j), img_gx.at<float>(i, j));//求角度
        }
    }


    /* step3:对梯度幅值进行非极大值抑制
    首先将角度划分成四个方向范围:水平(0°)、45°、垂直(90°)、135°
    */
    Mat Nms = Mat::zeros(rows, cols, CV_32FC1);//定义一个非极大值抑制图像，float型
    for (int i = 0; i < rows; i++)
    {
        for (int j = 0; j < cols; j++)
        {
            if (img_dir.at<float>(i, j) <= 22.5 && img_dir.at<float>(i, j) >= 0 || img_dir.at<float>(i, j) >= 157.5 && img_dir.at<float>(i, j) <= 202.5
                || img_dir.at<float>(i, j) >= 337.5 && img_dir.at<float>(i, j) <= 360)
                img_dir.at<float>(i, j) = 0;

            else if (img_dir.at<float>(i, j) > 22.5 && img_dir.at<float>(i, j) <= 67.5 || img_dir.at<float>(i, j) > 202.5 && img_dir.at<float>(i, j) <= 247.5)
                img_dir.at<float>(i, j) = 45;
            else if (img_dir.at<float>(i, j) > 67.5 && img_dir.at<float>(i, j) <= 112.5 || img_dir.at<float>(i, j) > 247.5 && img_dir.at<float>(i, j) <= 292.5)
                img_dir.at<float>(i, j) = 90;
            else if (img_dir.at<float>(i, j) > 112.5 && img_dir.at<float>(i, j) < 157.5 || img_dir.at<float>(i, j) > 292.5 && img_dir.at<float>(i, j) < 337.5)
                img_dir.at<float>(i, j) = 135;
        }
    }

    for (int i = 1; i < rows - 1; i++)
    {
        for (int j = 1; j < cols - 1; j++)
        {
            if (img_dir.at<float>(i, j) == 90 && img_g.at<float>(i, j) == max(img_g.at<float>(i, j), max(img_g.at<float>(i, j + 1), img_g.at<float>(i, j - 1))))
                Nms.at<float>(i, j) = img_g.at<float>(i, j);
            else if (img_dir.at<float>(i, j) == 45 && img_g.at<float>(i, j) == max(img_g.at<float>(i, j), max(img_g.at<float>(i - 1, j + 1), img_g.at<float>(i + 1, j - 1))))
                Nms.at<float>(i, j) = img_g.at<float>(i, j);
            else if (img_dir.at<float>(i, j) == 0 && img_g.at<float>(i, j) == max(img_g.at<float>(i, j), max(img_g.at<float>(i - 1, j), img_g.at<float>(i + 1, j))))
                Nms.at<float>(i, j) = img_g.at<float>(i, j);
            else if (img_dir.at<float>(i, j) == 135 && img_g.at<float>(i, j) == max(img_g.at<float>(i, j), max(img_g.at<float>(i - 1, j - 1), img_g.at<float>(i + 1, j + 1))))
                Nms.at<float>(i, j) = img_g.at<float>(i, j);
        }
    }

    /*step4:双阈值检测和连接边缘
    */
    Mat img_dst = Mat::zeros(rows, cols, CV_32FC1);//定义一个双阈值图像，float型
    double TH, TL;
    double maxVal = 0;//必须为double类型，且必须赋初值，否则报错
    Nms.convertTo(Nms, CV_64FC1); //为了计算，将非极大值抑制图像转为double型
    minMaxLoc(Nms, NULL, &maxVal, NULL, NULL); //求矩阵 Nms最大值
    TH = 0.5 * maxVal;//高阈值
    TL = 0.3 * maxVal;//低阈值
    for (int i = 0; i < rows; i++)
    {
        for (int j = 0; j < cols; j++)
        {
            if (Nms.at<double>(i, j) < TL)
                img_dst.at<float>(i, j) = 0;
            else if (Nms.at<double>(i, j) > TH)
                img_dst.at<float>(i, j) = 1;
            else if (Nms.at<double>(i - 1, j - 1) < TL || Nms.at<double>(i - 1, j) < TL || Nms.at<double>(i - 1, j + 1) < TL ||
                Nms.at<double>(i, j - 1) < TL || Nms.at<double>(i, j + 1) < TL || Nms.at<double>(i + 1, j - 1) < TL ||
                Nms.at<double>(i + 1, j) < TL || Nms.at<double>(i + 1, j + 1) < TL)
                img_dst.at<float>(i, j) = 1;
        }
    }

    imshow("非极大值抑制图", Nms);
    imshow(" 边缘检测图", img_dst);
    imwrite(" 边缘检测效果图.jpg", img_dst);//保存图像
    waitKey(0);
    return 0;

```

